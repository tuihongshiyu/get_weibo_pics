import requestsimport urllib.requestfrom bs4 import BeautifulSoupimport pymysqlimport typesimport timeimport reimport os# from .list import list_getfrom multiprocessing import PoolPIC_PATH = '/Users/HirosueRyouko/Pictures/From Weibo/'list_path = PIC_PATHdef show_picpath():    print('PIC_PATH: ', PIC_PATH)def set_picpath(PIC_PATH_new):    PIC_PATH = str(PIC_PATH_new)    show_picpath()def error_test(user_id, test_page):    main(user_id, test_page)def get_time():    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))def download_pic(url, name, user_id, path=PIC_PATH):    pic = requests.get(url)    if not os.path.exists(path + user_id):        os.mkdir(path + user_id)    if os.path.exists(path + user_id + '/' + name + '.jpg'):        return True    # print(path + user_id + '/' + name + '.jpg')    f = open(path + user_id + '/' + name + '.jpg', 'wb')    f.write(pic.content)    f.close()    return Falsedef main(user_id=5416247360, test_page=None, page_begin=1, path=PIC_PATH):    user_id = str(user_id)    containerid = get_containerid(user_id)    page_no = page_begin    Downloaded_num = 0    headers = {        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36'    }    if not test_page == None:  # FOR TEST        print('-------Test Begin')        page_no = test_page        url = 'http://m.weibo.cn/container/getIndex?type=uid&value=' + str(            user_id) + '&containerid=' + containerid + '&page=' + str(page_no)        # 所用api为移动端        page = requests.get(url, headers=headers)        soup = str(BeautifulSoup(page.text, 'lxml'))        soup_dic = str2dic(soup)        print(soup_dic['cards'])        if (soup_dic == 'Error'):            print('Error in Page :', page_no)            page_no = page_no + 1        elif soup_dic['cards'] == []:            # print('--------All things are done')            return        else:            pics_info, top_info = get_dic_info(soup_dic)            print(pics_info)        return    print('-------Downloading Bgein,ID : ' + user_id)    while (True):        url = 'http://m.weibo.cn/container/getIndex?type=uid&value=' + user_id + '&containerid=' + containerid + '&page=' + str(            page_no)        page = requests.get(url, headers=headers)        soup = str(BeautifulSoup(page.text, 'lxml'))        soup_dic = str2dic(soup)        if (soup_dic == 'Error'):            print('Error in Page :', page_no)            page_no = page_no + 1        elif soup_dic['cards'] == []:            # print('-------'+user_id+'Done\n','-------Till : ',get_time())            return        else:            pics_info, top_info = get_dic_info(soup_dic)            pics_info['user_id'] = user_id            print('id : ', user_id, ' Page: ', pics_info['page'], ' Num of urls: ', len(pics_info['url']))            pic_url = pics_info['url']            id = pics_info['id']            url_downloaded = []            info2mysql(pics_info)            for i in range(len(pic_url)):                if pic_url[i] in url_downloaded:                    continue                else:                    url_downloaded.append(pic_url[i])                Downloaded = download_pic(pic_url[i], id[i], user_id)                if Downloaded == True and len(url_downloaded) >= top_info['num_top']:                    Downloaded_num = Downloaded_num + 1                if Downloaded_num >= 7:                    # print(' -------Already Downloaded\n','-------All things are done\n','-------Till : ',get_time())                    return None            page_no = page_no + 1            # time.sleep(5)def get_containerid(user_id='5416247360'):    url = 'http://m.weibo.cn/container/getIndex?type=uid&value=' + user_id    page = requests.get(url)    soup = str(BeautifulSoup(page.text, 'lxml'))    soup_str = soup[15:-18]    soup_dic = str2dic(soup_str)    return soup_dic['tabsInfo']['tabs'][1]['containerid']def str2dic(str):    str = str.replace("true", '1')    str = str.replace("false", '0')    str = str.replace("null", '0')    pat = re.compile(r'<([^<>]*)>')    str = pat.sub('', str)    try:        dic = eval(str)    except:        str = str.replace(",\"", '\n\"')        pat = re.compile(r'/"([^/"]*)"')        str = pat.sub('', str)        return 'Error'    return dicdef get_dic_info(dic):    time = ''    page_info = {}    top_info = {'is_top': 0, 'num_top': 0}    page_info['page'] = dic['cardlistInfo']['page']    page_info['url'] = {}    page_info['id'] = {}    page_info['createdat'] = {}    num = 0    num2 = 0    for i in range(len(dic['cards'])):        try:            card = dic['cards'][i]['mblog']            card_str = str(dic['cards'][i]['mblog'])            createdat = sinatime2format(card['created_at'])            page_info['url'][num] = (card['original_pic']).replace('\\', '')            page_info['id'][num] = card['id']            page_info['createdat'][num] = createdat            num = num + 1            # pics_urls=re.findall('\'url\': \'.*.jpg\'',card_str)            if not re.search('retweeted_status', card_str) and re.search('\'pics\'', card_str):                for j in range(len(card['pics'])):                    pic_url = card['pics'][j]['large']['url'].replace('\\', '')                    page_info['url'][num] = pic_url                    page_info['id'][num] = card['pics'][j]['pid']                    page_info['createdat'][num] = createdat                    num = num + 1        except:            None        try:            if i == 0 and card['isTop'] == 1:                top_info['is_top'] = 1                top_info['num_top'] = len(card['pics']) + 1        except:            None    return page_info, top_infodef is_num_by_except(str):    try:        int(str)        return True    except:        return Falsedef info2mysql(info):  # 将数据存储入本地的mysql,若出现编码错误，则忽略该条，同名文件会覆盖从前的数据库    acount = ['localhost', 'root', 'Tuihongshiyu5', 'weibo_pics']    host = acount[0]    user = acount[1]    password = acount[2]    database = acount[3]    user_id = 'user' + info['user_id']    Urls = info['url']    Id = info['id']    Createdat = info['createdat']    try:        db = pymysql.connect(host, user, password, database, charset='utf8')        print('CONNECTING SUCESSFULLY')    except:        print('CONNECTING ERROR')    cursor = db.cursor()    try:        cursor.execute("show tables" + ';')        tables = cursor.fetchall()        if tables == {} or (user_id,)not in cursor.fetchall():            sql1 = """CREATE TABLE """            sql2 = """ (                    createat datetime,                    url char(100) NOT NULL,                    id char(50),                    downloaded bool,                    primary key (url)                    )character SET=utf8;"""            sql = sql1 + user_id + sql2            cursor.execute(sql)        else:            None    except:        None    for i in range(len(Urls)):        sql = "insert ignore into " + user_id + """        values("""        createat = datetime2mysql(Createdat[i])        sql = sql + createat + ',\"' + Urls[i] + '\",'+ '\"' + str(Id[i]) + '\",'+ '0'+');'        try:            cursor.execute(sql)        except:            print(sql, '\nILLEGAL TEXT')            continue    db.commit()    db.close()def sinatime2format(sina_time):    if (sina_time[0:1] == '今天'):        time = (get_time('today')) + sina_time[-6:]    elif (sina_time[0:1] == '昨天'):        time = get_time('yesterday') + sina_time[-6:]    elif (len(sina_time) == 11):        time = (get_time())[0:5] + sina_time    else:        time = sina_time    return timedef datetime2mysql(time):    time = time.replace(':', '')    time = time.replace('-', '')    time = time.replace(' ', '')    if (len(time) != 14):        return time + '00'    else:        return timedef get_all():    list = list_get()    # print(list)    # print('Parent process %s.' % os.getpid())    p = Pool(len(list) + 1)    for i in range(len(list)):        p.apply_async(main, args=(list[i],))    print('Waiting for all subprocesses done...')    p.close()    p.join()    print('All subprocesses done.')# print(datetime2mysql('2014-14-14 14:14:14'))main()# print(sinatime2format('02-20 16:16'))# get_containerid()# error_test()# get_all()